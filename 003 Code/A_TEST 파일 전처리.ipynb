{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 베이스 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 단일 CSV 파일 경로 설정\n",
    "input_csv = 'blind_test/A_5.csv'\n",
    "file_name = os.path.basename(input_csv)\n",
    "file_prefix = os.path.splitext(file_name)[0]\n",
    "\n",
    "# 3. 출력 폴더 계층 생성: preprocessing_blind_A/A_5.csv\n",
    "root_output = 'preprocessing_blind_A'\n",
    "subfolder = file_name\n",
    "output_dir = os.path.join(root_output, subfolder)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2. CSV 읽기 및 전처리\n",
    "#    - Datetime 또는 colec_dt/clct_dt 컬럼 처리\n",
    "#    - 중복 Datetime 제거 (첫번째 값 유지)\n",
    "#    - cell_volt_* 컬럼 이름 통일\n",
    "#    - 분 단위 리샘플링 및 병합\n",
    "#    - Unnamed: 0 제거\n",
    "#    - 3.3V 미만 NaN, 날짜별 NaN 기준 제거\n",
    "#    - 선형 보간\n",
    "#    - 3.6V 기준 필터링\n",
    "#    - 첫/마지막 날짜 제외\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Datetime 처리\n",
    "if 'Datetime' in df.columns:\n",
    "    df.rename(columns={'Datetime': 'colec_dt'}, inplace=True)\n",
    "elif 'colec_dt' not in df.columns:\n",
    "    if 'clct_dt' in df.columns:\n",
    "        df.rename(columns={'clct_dt': 'colec_dt'}, inplace=True)\n",
    "    else:\n",
    "        raise KeyError(\"CSV에 'Datetime', 'colec_dt' 또는 'clct_dt' 컬럼이 없습니다.\")\n",
    "\n",
    "# datetime 변환\n",
    "df['colec_dt'] = pd.to_datetime(df['colec_dt'])\n",
    "\n",
    "# 중복 Datetime 제거: 첫번째 값만 남김\n",
    "df = df.drop_duplicates(subset=['colec_dt'], keep='first')\n",
    "\n",
    "# cell_volt 컬럼명 통일\n",
    "if not any(col.startswith('cell_volt_') for col in df.columns):\n",
    "    rename_map = {col: f\"cell_volt_{int(col.split('_')[-1])}\" \n",
    "                  for col in df.columns \n",
    "                  if col.startswith('cel_volt_') and col.split('_')[-1].isdigit()}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# 분 단위 타임라인 생성 및 병합\n",
    "timeline = pd.date_range(start=df['colec_dt'].min(),\n",
    "                         end=df['colec_dt'].max(), freq='min')\n",
    "merged = pd.merge(\n",
    "    pd.DataFrame({'colec_dt': timeline}),\n",
    "    df, on='colec_dt', how='left'\n",
    ")\n",
    "\n",
    "# Unnamed: 0 제거\n",
    "merged.drop(columns=[c for c in ['Unnamed: 0'] if c in merged.columns], inplace=True)\n",
    "\n",
    "# cell_volt 컬럼 리스트\n",
    "volt_cols = [c for c in merged.columns if c.startswith('cell_volt_')]\n",
    "\n",
    "# 3.3V 미만 NaN 처리\n",
    "merged.loc[merged['cell_volt_1'] < 3.3, volt_cols] = np.nan\n",
    "\n",
    "# 날짜 컬럼 및 NaN 기준 제거\n",
    "merged['date'] = merged['colec_dt'].dt.date\n",
    "nan_thresh = 1400\n",
    "drop_dates = merged.groupby('date')['cell_volt_1'].apply(lambda x: x.isna().sum())\n",
    "merged = merged[~merged['date'].isin(drop_dates[drop_dates > nan_thresh].index)]\n",
    "merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 선형 보간\n",
    "merged[volt_cols] = merged[volt_cols].interpolate()\n",
    "\n",
    "# 3.6V 유효 기준 필터링\n",
    "valid_req = 400 * len(volt_cols)\n",
    "valid_dates = merged.groupby('date')[volt_cols].apply(lambda x: (x >= 3.6).sum().sum())\n",
    "merged = merged[merged['date'].isin(valid_dates[valid_dates >= valid_req].index)]\n",
    "merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 첫/마지막 날짜 제외\n",
    "dates = merged['date'].unique()\n",
    "if len(dates) > 2:\n",
    "    merged = merged[~merged['date'].isin([dates[0], dates[-1]])]\n",
    "    merged.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 4. NumPy 배열 저장 (float32)\n",
    "unique_dates = merged['date'].unique()\n",
    "for col in volt_cols:\n",
    "    arr = np.stack([\n",
    "        merged[merged['date'] == d][col].to_numpy(dtype=np.float32)\n",
    "        for d in unique_dates\n",
    "    ])  # shape: (n_dates, 1440)\n",
    "    save_path = os.path.join(output_dir, f\"{file_prefix}_{col}.npy\")\n",
    "    np.save(save_path, arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1440이 아닌 행이 있는 날짜·채널 ===\n",
      "2022-07-19 | cell_volt_1 | rows: 1455\n",
      "2022-08-22 | cell_volt_1 | rows: 1458\n",
      "2022-07-19 | cell_volt_2 | rows: 1455\n",
      "2022-08-22 | cell_volt_2 | rows: 1458\n",
      "2022-07-19 | cell_volt_3 | rows: 1455\n",
      "2022-08-22 | cell_volt_3 | rows: 1458\n",
      "2022-07-19 | cell_volt_4 | rows: 1455\n",
      "2022-08-22 | cell_volt_4 | rows: 1458\n",
      "2022-07-19 | cell_volt_5 | rows: 1455\n",
      "2022-08-22 | cell_volt_5 | rows: 1458\n",
      "2022-07-19 | cell_volt_6 | rows: 1455\n",
      "2022-08-22 | cell_volt_6 | rows: 1458\n",
      "2022-07-19 | cell_volt_7 | rows: 1455\n",
      "2022-08-22 | cell_volt_7 | rows: 1458\n",
      "2022-07-19 | cell_volt_8 | rows: 1455\n",
      "2022-08-22 | cell_volt_8 | rows: 1458\n",
      "2022-07-19 | cell_volt_9 | rows: 1455\n",
      "2022-08-22 | cell_volt_9 | rows: 1458\n",
      "2022-07-19 | cell_volt_10 | rows: 1455\n",
      "2022-08-22 | cell_volt_10 | rows: 1458\n",
      "2022-07-19 | cell_volt_11 | rows: 1455\n",
      "2022-08-22 | cell_volt_11 | rows: 1458\n",
      "2022-07-19 | cell_volt_12 | rows: 1455\n",
      "2022-08-22 | cell_volt_12 | rows: 1458\n",
      "2022-07-19 | cell_volt_13 | rows: 1455\n",
      "2022-08-22 | cell_volt_13 | rows: 1458\n",
      "2022-07-19 | cell_volt_14 | rows: 1455\n",
      "2022-08-22 | cell_volt_14 | rows: 1458\n"
     ]
    }
   ],
   "source": [
    "# unique_dates, volt_cols, merged가 이미 정의된 상태에서 실행\n",
    "\n",
    "bad_records = []\n",
    "\n",
    "# 채널별로 날짜별 행 개수 체크\n",
    "for col in volt_cols:\n",
    "    # 날짜별 그룹 크기 구하기\n",
    "    counts = merged.groupby('date')[col].size()\n",
    "    # 1440이 아닌 항목만 필터\n",
    "    bad = counts[counts != 1440]\n",
    "    for date, cnt in bad.items():\n",
    "        bad_records.append((date, col, cnt))\n",
    "\n",
    "# 결과 출력\n",
    "if bad_records:\n",
    "    print(\"=== 1440이 아닌 행이 있는 날짜·채널 ===\")\n",
    "    for date, col, cnt in bad_records:\n",
    "        print(f\"{date} | {col} | rows: {cnt}\")\n",
    "else:\n",
    "    print(\"모든 날짜·채널이 1440행을 가집니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1440행이 아닌 날짜 중, Datetime이 중복된 행들 ===\n",
      "                 colec_dt  bms_no      eqp_no  bsc_fg_no  bank_no  rack_no  \\\n",
      "36150 2022-07-19 02:30:00     1.0  20000003.0        1.0      1.0      6.0   \n",
      "36151 2022-07-19 02:30:00     1.0  20000003.0        1.0      1.0      7.0   \n",
      "36152 2022-07-19 02:31:00     1.0  20000003.0        1.0      1.0      6.0   \n",
      "36153 2022-07-19 02:31:00     1.0  20000003.0        1.0      1.0      7.0   \n",
      "36154 2022-07-19 02:32:00     1.0  20000003.0        1.0      1.0      6.0   \n",
      "...                   ...     ...         ...        ...      ...      ...   \n",
      "70786 2022-08-22 03:15:00     1.0  20000003.0        1.0      1.0      7.0   \n",
      "70787 2022-08-22 03:16:00     1.0  20000003.0        1.0      1.0      6.0   \n",
      "70788 2022-08-22 03:16:00     1.0  20000003.0        1.0      1.0      7.0   \n",
      "70789 2022-08-22 03:17:00     1.0  20000003.0        1.0      1.0      6.0   \n",
      "70790 2022-08-22 03:17:00     1.0  20000003.0        1.0      1.0      7.0   \n",
      "\n",
      "       string_no  module_no  cell_volt_1  cell_volt_2  ...  cell_volt_9  \\\n",
      "36150        1.0        9.0     3.422926     3.419926  ...     3.433926   \n",
      "36151        1.0        9.0     3.422931     3.419931  ...     3.433931   \n",
      "36152        1.0        9.0     3.422936     3.419936  ...     3.433936   \n",
      "36153        1.0        9.0     3.422941     3.419941  ...     3.433941   \n",
      "36154        1.0        9.0     3.422945     3.419945  ...     3.433945   \n",
      "...          ...        ...          ...          ...  ...          ...   \n",
      "70786        1.0        9.0     3.444160     3.441480  ...     3.446800   \n",
      "70787        1.0        9.0     3.444200     3.441600  ...     3.447000   \n",
      "70788        1.0        9.0     3.444240     3.441720  ...     3.447200   \n",
      "70789        1.0        9.0     3.444280     3.441840  ...     3.447400   \n",
      "70790        1.0        9.0     3.444320     3.441960  ...     3.447600   \n",
      "\n",
      "       cell_volt_10  cell_volt_11  cell_volt_12  cell_volt_13  cell_volt_14  \\\n",
      "36150      3.421926      3.425926      3.369853      3.424926      3.420390   \n",
      "36151      3.421931      3.425931      3.369862      3.424931      3.420397   \n",
      "36152      3.421936      3.425936      3.369872      3.424936      3.420404   \n",
      "36153      3.421941      3.425941      3.369881      3.424941      3.420411   \n",
      "36154      3.421945      3.425945      3.369891      3.424945      3.420418   \n",
      "...             ...           ...           ...           ...           ...   \n",
      "70786      3.446000      3.445320      3.442440      3.446160      3.445160   \n",
      "70787      3.446000      3.445400      3.441800      3.446200      3.445200   \n",
      "70788      3.446000      3.445480      3.441160      3.446240      3.445240   \n",
      "70789      3.446000      3.445560      3.440520      3.446280      3.445280   \n",
      "70790      3.446000      3.445640      3.439880      3.446320      3.445320   \n",
      "\n",
      "        1  20000003  1.1        date  \n",
      "36150 NaN       NaN  NaN  2022-07-19  \n",
      "36151 NaN       NaN  NaN  2022-07-19  \n",
      "36152 NaN       NaN  NaN  2022-07-19  \n",
      "36153 NaN       NaN  NaN  2022-07-19  \n",
      "36154 NaN       NaN  NaN  2022-07-19  \n",
      "...    ..       ...  ...         ...  \n",
      "70786 NaN       NaN  NaN  2022-08-22  \n",
      "70787 NaN       NaN  NaN  2022-08-22  \n",
      "70788 NaN       NaN  NaN  2022-08-22  \n",
      "70789 NaN       NaN  NaN  2022-08-22  \n",
      "70790 NaN       NaN  NaN  2022-08-22  \n",
      "\n",
      "[66 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# merged, unique_dates 등이 이미 정의된 상태에서 실행\n",
    "\n",
    "# 1) 날짜별 전체 행 수 계산\n",
    "counts = merged.groupby('date').size()\n",
    "\n",
    "# 2) 1440이 아닌 날짜만 추출\n",
    "bad_dates = counts[counts != 1440].index\n",
    "\n",
    "# 3) 해당 날짜의 데이터만 필터\n",
    "bad_df = merged[merged['date'].isin(bad_dates)]\n",
    "\n",
    "# 4) Datetime(여기서는 colec_dt) 중복 행 찾기\n",
    "duplicates = bad_df[bad_df['colec_dt'].duplicated(keep=False)]\n",
    "\n",
    "# 5) 결과 출력\n",
    "if not duplicates.empty:\n",
    "    print(\"=== 1440행이 아닌 날짜 중, Datetime이 중복된 행들 ===\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"중복된 Datetime 행이 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bsc_fg_no가 2일때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_1.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_2.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_3.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_4.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_5.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_6.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_7.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_8.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_9.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_10.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_11.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_12.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_13.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_1/A_2_cell_volt_14.npy | shape=(27, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_1.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_2.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_3.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_4.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_5.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_6.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_7.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_8.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_9.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_10.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_11.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_12.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_13.npy | shape=(26, 1440), dtype=float32\n",
      "Saved: preprocessing_blind_A/A_2.csv_2/A_2_cell_volt_14.npy | shape=(26, 1440), dtype=float32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 단일 CSV 파일 경로 및 기본 설정\n",
    "input_csv = 'blind_test/A_2.csv'\n",
    "file_name = os.path.basename(input_csv)       # 'A_2.csv'\n",
    "file_prefix = os.path.splitext(file_name)[0]  # 'A_2'\n",
    "root_output = 'preprocessing_blind_A'\n",
    "\n",
    "# 전체 데이터 로드\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# bsc_fg_no별로 분리 처리\n",
    "for bank_no in [1, 2]:\n",
    "    df_bank = df[df['bsc_fg_no'] == bank_no].copy()\n",
    "    if df_bank.empty:\n",
    "        print(f\"No data for bsc_fg_no={bank_no}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 3. 출력 폴더 계층: preprocessing_blind_A/A_2.csv_1, A_2.csv_2\n",
    "    subfolder = f\"{file_name}_{bank_no}\"  # 'A_2.csv_1' 등\n",
    "    output_dir = os.path.join(root_output, subfolder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. 시간 컬럼 처리: Datetime 또는 colec_dt/clct_dt -> colec_dt\n",
    "    if 'Datetime' in df_bank.columns:\n",
    "        df_bank.rename(columns={'Datetime': 'colec_dt'}, inplace=True)\n",
    "    elif 'colec_dt' not in df_bank.columns:\n",
    "        if 'clct_dt' in df_bank.columns:\n",
    "            df_bank.rename(columns={'clct_dt': 'colec_dt'}, inplace=True)\n",
    "        else:\n",
    "            raise KeyError(\"CSV에 'Datetime', 'colec_dt' 또는 'clct_dt' 컬럼이 없습니다.\")\n",
    "\n",
    "    # 2. 전압 컬럼 이름 정규화: cel_volt_ -> cell_volt_\n",
    "    if not any(col.startswith('cell_volt_') for col in df_bank.columns):\n",
    "        rename_dict = {}\n",
    "        for col in df_bank.columns:\n",
    "            if col.startswith('cel_volt_'):\n",
    "                num = col.replace('cel_volt_', '')\n",
    "                if num.isdigit():\n",
    "                    rename_dict[col] = f'cell_volt_{int(num)}'\n",
    "        if rename_dict:\n",
    "            df_bank.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    # datetime 변환 및 리샘플링\n",
    "    df_bank['colec_dt'] = pd.to_datetime(df_bank['colec_dt'])\n",
    "    start, end = df_bank['colec_dt'].min(), df_bank['colec_dt'].max()\n",
    "    full_time = pd.DataFrame({'colec_dt': pd.date_range(start, end, freq='min')})\n",
    "    merged = pd.merge(full_time, df_bank, on='colec_dt', how='left')\n",
    "\n",
    "    # 불필요 컬럼 제거\n",
    "    if 'Unnamed: 0' in merged.columns:\n",
    "        merged.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    # 채널 목록 추출\n",
    "    volt_cols = [c for c in merged.columns if c.startswith('cell_volt_')]\n",
    "    if not volt_cols:\n",
    "        print(f\"No voltage columns found for bank {bank_no}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 5. 전압 <3.3V -> NaN\n",
    "    merged.loc[merged[volt_cols[0]] < 3.3, volt_cols] = np.nan\n",
    "    merged['date'] = merged['colec_dt'].dt.date\n",
    "\n",
    "    # 날짜별 NaN 기준으로 제거\n",
    "    nan_thr = 1400\n",
    "    valid_days = merged.groupby('date')[volt_cols[0]].apply(lambda x: x.isna().sum() <= nan_thr)\n",
    "    merged = merged[merged['date'].isin(valid_days[valid_days].index)].reset_index(drop=True)\n",
    "\n",
    "    # 6. 선형 보간\n",
    "    merged[volt_cols] = merged[volt_cols].interpolate(method='linear')\n",
    "\n",
    "    # 3.6V 기준 필터링\n",
    "    vt_thr = 3.6\n",
    "    req_count = 400 * len(volt_cols)\n",
    "    keep_days = merged.groupby('date')[volt_cols].apply(lambda df_day: (df_day >= vt_thr).sum().sum() >= req_count)\n",
    "    merged = merged[merged['date'].isin(keep_days[keep_days].index)].reset_index(drop=True)\n",
    "\n",
    "    # 7. 첫/마지막 날짜 제외\n",
    "    dates = merged['date'].unique()\n",
    "    if len(dates) <= 2:\n",
    "        print(f\"Not enough valid days for bank {bank_no}, skipping.\")\n",
    "        continue\n",
    "    merged = merged[~merged['date'].isin([dates[0], dates[-1]])].reset_index(drop=True)\n",
    "\n",
    "    # 8. NumPy 배열로 저장 (float32)\n",
    "    unique_dates = merged['date'].unique()\n",
    "    for col in volt_cols:\n",
    "        arr2d = np.stack([\n",
    "            merged[merged['date'] == d][col].to_numpy(dtype=np.float32)\n",
    "            for d in unique_dates\n",
    "        ])  # shape: (n_dates, 1440)\n",
    "        save_path = os.path.join(output_dir, f\"{file_prefix}_{col}.npy\")\n",
    "        np.save(save_path, arr2d)\n",
    "        print(f\"Saved: {save_path} | shape={arr2d.shape}, dtype={arr2d.dtype}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
